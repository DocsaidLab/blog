<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-feat-fusion/nasfpn" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.2.1">
<title data-rh="true">NAS-FPN | DOCSAID</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://docsaid.org/en/img/docsaid-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://docsaid.org/en/img/docsaid-social-card.jpg"><meta data-rh="true" property="og:url" content="https://docsaid.org/en/papers/feat-fusion/nasfpn"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="zh_hant"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-papers-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-papers-current"><meta data-rh="true" property="og:title" content="NAS-FPN | DOCSAID"><meta data-rh="true" name="description" content="Money Talks: NAS-FPN"><meta data-rh="true" property="og:description" content="Money Talks: NAS-FPN"><link data-rh="true" rel="icon" href="/en/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://docsaid.org/en/papers/feat-fusion/nasfpn"><link data-rh="true" rel="alternate" href="https://docsaid.org/papers/feat-fusion/nasfpn" hreflang="zh-hant"><link data-rh="true" rel="alternate" href="https://docsaid.org/en/papers/feat-fusion/nasfpn" hreflang="en"><link data-rh="true" rel="alternate" href="https://docsaid.org/papers/feat-fusion/nasfpn" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/en/blog/rss.xml" title="DOCSAID RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/en/blog/atom.xml" title="DOCSAID Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel="stylesheet" href="/en/assets/css/styles.cfea8505.css">
<script src="/en/assets/js/runtime~main.d3a72e51.js" defer="defer"></script>
<script src="/en/assets/js/main.0442d4b1.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/en/"><div class="navbar__logo"><img src="/en/img/docsaid_logo.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/en/img/docsaid_logo_white.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href="/en/docs/">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/en/papers/intro">Papers</a><a class="navbar__item navbar__link" href="/en/blog">Blog</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/papers/feat-fusion/nasfpn" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hant">繁體中文</a></li><li><a href="/en/papers/feat-fusion/nasfpn" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li></ul></div><a href="https://github.com/DocsaidLab" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex="-1" class="sidebarLogo_isFc" href="/en/"><img src="/en/img/docsaid_logo.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/en/img/docsaid_logo_white.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/intro">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/papers/category/multimodel">MultiModel</a><button aria-label="Expand sidebar category &#x27;MultiModel&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/en/papers/category/featurefusion">FeatureFusion</a><button aria-label="Collapse sidebar category &#x27;FeatureFusion&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/papers/feat-fusion/fpn">FPN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/papers/feat-fusion/panet">PANet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/papers/feat-fusion/hourglass">Hourglass</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/en/papers/feat-fusion/nasfpn">NAS-FPN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/papers/feat-fusion/unetpp">UNet++</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/papers/category/objectdetection">ObjectDetection</a><button aria-label="Expand sidebar category &#x27;ObjectDetection&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/en/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/en/papers/category/featurefusion"><span itemprop="name">FeatureFusion</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">NAS-FPN</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>NAS-FPN</h1>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="money-talks-nas-fpn">Money Talks: NAS-FPN<a href="#money-talks-nas-fpn" class="hash-link" aria-label="Direct link to Money Talks: NAS-FPN" title="Direct link to Money Talks: NAS-FPN">​</a></h2>
<p><strong><a href="https://arxiv.org/abs/1904.07392" target="_blank" rel="noopener noreferrer">NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection (2019.04)</a></strong></p>
<hr>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>The following content is compiled by ChatGPT-4, with manual proofreading, editing, and additional explanations.</p></div></div>
<hr>
<p>Since the advent of FPN, feature fusion has been a hotly debated topic. Here&#x27;s a chronological list:</p>
<ul>
<li>2017.01 -&gt; <a href="https://arxiv.org/abs/1701.06659" target="_blank" rel="noopener noreferrer">DSSD : Deconvolutional single shot detector</a></li>
<li>2017.07 -&gt; <a href="https://arxiv.org/abs/1707.01691" target="_blank" rel="noopener noreferrer">RON: reverse connection with objectness prior networks for object detection</a></li>
<li>2017.07 -&gt; <a href="https://arxiv.org/abs/1707.06484" target="_blank" rel="noopener noreferrer">Deep layer aggregation</a></li>
<li>2017.09 -&gt; <a href="https://arxiv.org/abs/1709.05788" target="_blank" rel="noopener noreferrer">StairNet: top-down semantic aggregation for accurate one shot detection</a></li>
<li>2017.11 -&gt; <a href="https://arxiv.org/abs/1711.06897" target="_blank" rel="noopener noreferrer">Single-shot refinement neural network for object detection</a></li>
<li>2018.03 -&gt; <a href="https://arxiv.org/abs/1803.01534" target="_blank" rel="noopener noreferrer">Path Aggregation Network for Instance Segmentation</a> (PANet here)</li>
<li>2018.08 -&gt; <a href="https://ieeexplore.ieee.org/document/8578160" target="_blank" rel="noopener noreferrer">Scale-transferrable object detection</a></li>
<li>2018.08 -&gt; <a href="https://arxiv.org/abs/1808.07993" target="_blank" rel="noopener noreferrer">Deep feature pyramid reconfiguration for object detection</a></li>
<li>2018.10 -&gt; <a href="https://link.springer.com/chapter/10.1007/978-3-030-01228-1_15#chapter-info" target="_blank" rel="noopener noreferrer">Parallel feature pyramid network for object detection</a></li>
</ul>
<p>PANet is the most commonly heard of among these. Besides PANet, the aforementioned papers have hundreds to thousands of citations. It&#x27;s recommended to give them a read when you have time.</p>
<p>So, which one should you choose?</p>
<p>Google wanted to know the answer too, which led to the publication of the paper NAS-FPN.</p>
<p>Can you guess the core concept? &quot;I don&#x27;t know which one&#x27;s better, so let&#x27;s use an algorithm…&quot;</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>Isn&#x27;t that a bit off? But then again, it&#x27;s so Google.</p><p>Remember the NasNet series? They&#x27;re about searching network architectures. Eventually, they even came up with another paper called EfficientNet, which you might have heard of.</p><p>Besides network architecture, chip design can also use NAS. Now, using NAS for feature fusion is just another practical move.</p></div></div>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="whats-nas">What&#x27;s NAS?<a href="#whats-nas" class="hash-link" aria-label="Direct link to What&#x27;s NAS?" title="Direct link to What&#x27;s NAS?">​</a></h2>
<p>NAS stands for Neural Architecture Search, a crucial research direction in deep learning. Its main goal is to automatically find the best neural network architecture to solve specific tasks. Neural network architectures typically consist of multiple layers, neurons, and connections, and the design of these architectures can have a significant impact on the performance of the model.</p>
<p>Traditionally, neural network design has been mostly a manual process, requiring extensive experimentation and tuning by experts, which is time-consuming and requires domain expertise. NAS aims to simplify this process by automating it, allowing machines to explore and discover the best neural network architectures.</p>
<p>In NAS, a search space is defined, containing variants of all possible neural network architectures. Then, using different search strategies such as genetic algorithms, reinforcement learning, evolutionary algorithms, etc., the system automatically generates, evaluates, and selects these architectures to find the best one for a specific task.</p>
<p>Generally, the pros and cons of NAS are:</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="pros">Pros<a href="#pros" class="hash-link" aria-label="Direct link to Pros" title="Direct link to Pros">​</a></h3>
<ul>
<li><strong>Automation</strong>: Can automatically explore and find the best neural network architecture, reducing the need for manual tuning and design work, thus saving time and resources.</li>
<li><strong>Optimization</strong>: Can find the best neural network structure for specific tasks and datasets, improving model performance and potentially surpassing manually designed models in some cases.</li>
<li><strong>Flexibility</strong>: Not limited to specific tasks or architectures, can adapt to different application scenarios, and generate models suitable for specific requirements.</li>
<li><strong>Innovation</strong>: Can lead to the discovery of new neural network structures, potentially bringing innovative model architectures and further advancing deep learning.</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="cons">Cons<a href="#cons" class="hash-link" aria-label="Direct link to Cons" title="Direct link to Cons">​</a></h3>
<ul>
<li><strong>Computational Resource Consumption</strong>: Search process may require significant computational resources, including GPUs or TPUs, and a considerable amount of time, which may limit its practical application.</li>
<li><strong>Complexity</strong>: Size of the search space and the number of possible combinations may make the search process very complex, requiring more advanced algorithms and techniques for effective search.</li>
<li><strong>High Dependency on Datasets</strong>: Found best architectures may heavily depend on the specific dataset used for the search, and cannot guarantee superior performance on other datasets.</li>
<li><strong>Stochasticity</strong>: Search process may have some level of randomness, different search runs may yield different results, posing a challenge to the stability of the results.</li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="actually-there-are-more-cons">Actually, There Are More Cons<a href="#actually-there-are-more-cons" class="hash-link" aria-label="Direct link to Actually, There Are More Cons" title="Direct link to Actually, There Are More Cons">​</a></h2>
<p>After reading about the pros and cons of NAS, you might be particularly interested in its flexibility and innovation. But the reality is that over 90% or more of practitioners lack the resources to build their own search systems, often having to rely on the results brought by this technology. This immediately leads to another question:</p>
<ul>
<li><strong>Does my use case match the paper&#x27;s scenario?</strong></li>
</ul>
<p>Here, the use case includes the feature distributions of inference data, training data, the search space for solving problems, etc. If there&#x27;s a chance that the answer is no, then this optimized architecture might, perhaps, not be…</p>
<ul>
<li><strong>Suitable.</strong></li>
</ul>
<p>So, why talk about this paper?</p>
<p>Firstly, we might be part of that 10% who are interested. This paper demonstrates how to design a search architecture and find the most suitable feature fusion method for one&#x27;s own usage scenario. Secondly, it showcases some results obtained from automated searches, which can provide some inspiration for future designs.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="problem-solving">Problem Solving<a href="#problem-solving" class="hash-link" aria-label="Direct link to Problem Solving" title="Direct link to Problem Solving">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="nas-fpn-model-design">NAS-FPN Model Design<a href="#nas-fpn-model-design" class="hash-link" aria-label="Direct link to NAS-FPN Model Design" title="Direct link to NAS-FPN Model Design">​</a></h3>
<p><img decoding="async" loading="lazy" alt="nasfpn_1" src="/en/assets/images/nasfpn_1-01b0062e70541234d43589331cde5246.jpg" width="1024" height="284" class="img_ev3q"></p>
<p>The primary goal of this study was to find a better FPN architecture. In the academic discourse, a model typically begins with a basic structure called the Backbone, which can be freely swapped, such as ResNet, MobileNet, etc.</p>
<p>Following the Backbone is the Neck, where FPN typically resides. Its main job is multiscale feature concatenation, which is the focus here.</p>
<p>It&#x27;s worth mentioning that in this study, the authors used a framework called &quot;RetinaNet&quot; as the foundation. RetinaNet&#x27;s backbone employs ResNet, while its neck employs FPN.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>The main theme of the RetinaNet paper is actually FocalLoss. The RetinaNet architecture inside it is a simple combination for applying FocalLoss.</p></div></div>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="merging-cells">Merging Cells<a href="#merging-cells" class="hash-link" aria-label="Direct link to Merging Cells" title="Direct link to Merging Cells">​</a></h3>
<p><img decoding="async" loading="lazy" alt="nasfpn_2" src="/en/assets/images/nasfpn_2-02f26c48d4b0f0596bd9e17e923084a6.jpg" width="1024" height="335" class="img_ev3q"></p>
<p>In NAS-FPN, a new concept called &quot;Merging Cell&quot; was proposed based on the original FPN design.</p>
<p>A Merging Cell is a small module responsible for &quot;merging&quot; two different input feature layers into a new output feature layer. This merging process consists of the following steps:</p>
<ol>
<li>Select the first feature layer: Choose one from multiple candidate feature layers (could be C3, C4, C5, etc.), denoted as hi.</li>
<li>Select the second feature layer: Again, choose one from multiple candidate feature layers, denoted as hj.</li>
<li>Determine the size of the output feature: Choose a resolution size, which will be the size of the new merged feature layer.</li>
<li>Select the merge operation: Use a specific mathematical operation (such as addition or global pooling) to merge hi and hj.</li>
</ol>
<p>In step 4, as shown in the diagram, two binary operations were designed: summation and global pooling. These operations were chosen because they are simple and efficient, requiring no additional trainable parameters.</p>
<p>If hi and hj have different sizes, upsampling or downsampling is applied to make them the same size before merging. The merged new feature layer undergoes a ReLU activation function, a 3×3 convolutional layer, and a BatchNorm layer to enhance its expressive capability. Thus, FPN can continuously merge and improve feature layers through multiple such Merging Cells, ultimately generating a set of better multiscale feature layers (P3, P4, P5, etc.).</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="discussion">Discussion<a href="#discussion" class="hash-link" aria-label="Direct link to Discussion" title="Direct link to Discussion">​</a></h2>
<p>Experimental data shows that with the increase of training steps, the controller is able to generate better and better subnetwork architectures. This process reaches a stable state after about 8000 training steps, meaning the number of unique architectures added begins to converge.</p>
<p>Finally, based on the optimization results of rewards, the authors selected the architecture with the highest AP for further training and evaluation.</p>
<p>This architecture was sampled during the first 8000 steps of training and sampled multiple times in subsequent experiments.</p>
<p>Subsequently, the authors demonstrated the FPN architecture obtained by the NAS algorithm as follows:</p>
<p><img decoding="async" loading="lazy" alt="nasfpn_5" src="/en/assets/images/nasfpn_5-74aa9280cbf9836c059d825df38e640a.jpg" width="800" height="602" class="img_ev3q"></p>
<p>This diagram might look complex at first glance, but with annotations:</p>
<p><img decoding="async" loading="lazy" alt="nasfpn_3" src="/en/assets/images/nasfpn_3-55712a3bcdfaa8f0bcefb5c2ba165093.jpg" width="1024" height="523" class="img_ev3q"></p>
<p>With annotations, we can now take a closer look at the results of NAS-FPN.</p>
<p>Firstly, in the initial FPN (a), it&#x27;s not exactly FPN; it&#x27;s a &quot;FPN-like&quot; structure because it outputs feature maps differently and has a different data flow sequence, though it&#x27;s consistent with FPN in essence. However, the original FPN doesn’t have this many layers of convolutional layers.</p>
<p>Next, looking at the experimental results of NAS-FPN from (b) to (f), as AP scores keep improving, we can observe that the way of searching architectures ultimately verifies the design philosophy of the PANet paper, i.e., diagram (f):</p>
<ul>
<li>Data must be fused from top to bottom.</li>
<li>Data must then be fused from bottom to top.</li>
<li>Although the details might be slightly different, the essence is captured.</li>
</ul>
<p><img decoding="async" loading="lazy" alt="nasfpn_4" src="/en/assets/images/nasfpn_4-4fc798fa415af362fcbb494ab6b4349b.jpg" width="1024" height="472" class="img_ev3q"></p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>In previous research, feature fusion architectures have mostly been derived through manual design and experimentation. The reliability and scale of this approach have always been questioned. Indeed, experimental research, while providing insights, often has its value limited by the scale and design of the experiments.</p>
<p>Perhaps we can accept that the &quot;theoretical foundation&quot; of certain conclusions might be insufficient and acknowledge that conclusions derived through &quot;experimentation&quot; suffice. But how do we convince others that the scale of these experiments is sufficient?</p>
<p>However, NAS-FPN offers a new perspective on this issue, with a precise search architecture and unprecedented computational scale (perhaps no other company has the resources or willingness to spend on such computations). This not only confirms the correctness of PANet&#x27;s design philosophy but also reveals the potential inefficiencies in its connection method.</p>
<p>I believe this is the value of this paper. This method of combining NAS search results not only enhances the credibility of previous research but also provides new directions for future research.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2024-04-28T22:02:45.000Z" itemprop="dateModified">Apr 28, 2024</time></b> by <b>zephyr-sh</b></span></div></div></footer><div style="margin-top:3rem"> </div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/en/papers/feat-fusion/hourglass"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Hourglass</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/en/papers/feat-fusion/unetpp"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">UNet++</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#money-talks-nas-fpn" class="table-of-contents__link toc-highlight">Money Talks: NAS-FPN</a></li><li><a href="#whats-nas" class="table-of-contents__link toc-highlight">What&#39;s NAS?</a><ul><li><a href="#pros" class="table-of-contents__link toc-highlight">Pros</a></li><li><a href="#cons" class="table-of-contents__link toc-highlight">Cons</a></li></ul></li><li><a href="#actually-there-are-more-cons" class="table-of-contents__link toc-highlight">Actually, There Are More Cons</a></li><li><a href="#problem-solving" class="table-of-contents__link toc-highlight">Problem Solving</a><ul><li><a href="#nas-fpn-model-design" class="table-of-contents__link toc-highlight">NAS-FPN Model Design</a></li><li><a href="#merging-cells" class="table-of-contents__link toc-highlight">Merging Cells</a></li></ul></li><li><a href="#discussion" class="table-of-contents__link toc-highlight">Discussion</a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class="footer__links"><a class="footer__link-item" href="/en/docs">Docs</a><span class="footer__link-separator">·</span><a class="footer__link-item" href="/en/papers/intro">Papers</a><span class="footer__link-separator">·</span><a class="footer__link-item" href="/en/blog">Blog</a><span class="footer__link-separator">·</span><a href="https://github.com/DocsaidLab" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><span class="footer__link-separator">·</span><a href="https://docsaid.org/blog/terms-of-service" target="_blank" rel="noopener noreferrer" class="footer__link-item">TermsOfUse<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><span class="footer__link-separator">·</span><a href="https://docsaid.org/blog/privacy-policy" target="_blank" rel="noopener noreferrer" class="footer__link-item">Privacy Policy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 DOCSAID.</div></div></div></footer></div>
</body>
</html>