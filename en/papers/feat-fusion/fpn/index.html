<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-papers docs-version-current docs-doc-page docs-doc-id-feat-fusion/fpn" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.2.1">
<title data-rh="true">FPN | DOCSAID</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://docsaid.org/en/img/docsaid-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://docsaid.org/en/img/docsaid-social-card.jpg"><meta data-rh="true" property="og:url" content="https://docsaid.org/en/papers/feat-fusion/fpn"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="zh_hant"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-papers-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-papers-current"><meta data-rh="true" property="og:title" content="FPN | DOCSAID"><meta data-rh="true" name="description" content="Pyramid Architecture"><meta data-rh="true" property="og:description" content="Pyramid Architecture"><link data-rh="true" rel="icon" href="/en/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://docsaid.org/en/papers/feat-fusion/fpn"><link data-rh="true" rel="alternate" href="https://docsaid.org/papers/feat-fusion/fpn" hreflang="zh-hant"><link data-rh="true" rel="alternate" href="https://docsaid.org/en/papers/feat-fusion/fpn" hreflang="en"><link data-rh="true" rel="alternate" href="https://docsaid.org/papers/feat-fusion/fpn" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/en/blog/rss.xml" title="DOCSAID RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/en/blog/atom.xml" title="DOCSAID Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RDF83L9R4M"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RDF83L9R4M",{anonymize_ip:!0})</script><link rel="stylesheet" href="/en/assets/css/styles.cfea8505.css">
<script src="/en/assets/js/runtime~main.d3a72e51.js" defer="defer"></script>
<script src="/en/assets/js/main.0442d4b1.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/en/"><div class="navbar__logo"><img src="/en/img/docsaid_logo.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/en/img/docsaid_logo_white.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href="/en/docs/">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/en/papers/intro">Papers</a><a class="navbar__item navbar__link" href="/en/blog">Blog</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/papers/feat-fusion/fpn" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hant">繁體中文</a></li><li><a href="/en/papers/feat-fusion/fpn" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li></ul></div><a href="https://github.com/DocsaidLab" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex="-1" class="sidebarLogo_isFc" href="/en/"><img src="/en/img/docsaid_logo.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/en/img/docsaid_logo_white.png" alt="Docsaid Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b></b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/papers/intro">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/papers/category/multimodel">MultiModel</a><button aria-label="Expand sidebar category &#x27;MultiModel&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/en/papers/category/featurefusion">FeatureFusion</a><button aria-label="Collapse sidebar category &#x27;FeatureFusion&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/en/papers/feat-fusion/fpn">FPN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/papers/feat-fusion/panet">PANet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/papers/feat-fusion/hourglass">Hourglass</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/papers/feat-fusion/nasfpn">NAS-FPN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/papers/feat-fusion/unetpp">UNet++</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/papers/category/objectdetection">ObjectDetection</a><button aria-label="Expand sidebar category &#x27;ObjectDetection&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/en/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/en/papers/category/featurefusion"><span itemprop="name">FeatureFusion</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">FPN</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>FPN</h1>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="pyramid-architecture">Pyramid Architecture<a href="#pyramid-architecture" class="hash-link" aria-label="Direct link to Pyramid Architecture" title="Direct link to Pyramid Architecture">​</a></h2>
<p><strong><a href="https://arxiv.org/abs/1612.03144" target="_blank" rel="noopener noreferrer">Feature Pyramid Networks for Object Detection (2016.12)</a></strong></p>
<hr>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>The following content is compiled by ChatGPT-4, with manual proofreading, editing, and additional explanations.</p></div></div>
<hr>
<p>Consider a scenario.</p>
<p>Given the typical workflow of a convolutional neural network model: starting with inputting an original image, possibly with dimensions of 3 x 224 x 224, then passing through layers of downsampling, finally obtaining a high-dimensional semantic feature map, with dimensions possibly being 256 x 7 x 7. Typically, in a conventional model, the output is usually at a 1/32 scale, meaning, for example, with an original image of 224 x 224, the final feature map would be 7 x 7.</p>
<p>There are several ways to describe this feature map, you might have heard:</p>
<ul>
<li>Low-resolution feature map (because compared to the original image, the final feature map is only 1/32 in size).</li>
<li>High-dimensional semantic features (as it condenses the features of the entire image, carrying a larger receptive field).</li>
<li>Top-level features (bottom｜original -&gt; C1 -&gt; C2 -&gt; … -&gt; C5 ｜top)</li>
</ul>
<p>This design works well for classification tasks because classification can reference the content of the entire input image and output one or several possible classification results.</p>
<p>However, this approach doesn&#x27;t work for object detection. As mentioned earlier, this feature map is at a 1/32 scale. So, if there&#x27;s an object we want to detect, and its size in the image is smaller than 32 x 32 pixels, unfortunately, it will &quot;vanish&quot; during the downsampling process, as the model won&#x27;t see it in the final feature map.</p>
<p>Well, &quot;vanish&quot; might be a bit exaggerated. In reality, if the model uses convolutional operations for downsampling, the object might still be represented by nearby pixels.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>If you find this description a bit supernatural, that&#x27;s okay. In any case, the model will struggle to see it, as it would require more capacity to capture this tiny feature, ultimately affecting the overall performance.</p></div></div>
<p>This means if we want to improve object detection performance, we need to do something to retain these features.</p>
<p>Around the end of 2015, SSD was proposed:</p>
<ul>
<li><strong><a href="https://arxiv.org/abs/1512.02325" target="_blank" rel="noopener noreferrer">SSD: Single Shot MultiBox Detector (2015.12)</a></strong></li>
</ul>
<p>It aimed to improve upon YOLO v1.</p>
<p>It is based on the architecture of YOLO v1, where different-scale feature maps are added to the prediction head, and high-dimensional features (P3~P5) are merged for prediction, marking the first attempt at a pyramid feature hierarchy. While it was an earlier design, it can be considered a precursor to feature pyramid networks. Its drawback lies in its computational complexity and the inability of low-dimensional features to reference high-dimensional semantic features.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="problem-definition">Problem Definition<a href="#problem-definition" class="hash-link" aria-label="Direct link to Problem Definition" title="Direct link to Problem Definition">​</a></h2>
<p>In this paper, the authors clearly identify these main problems:</p>
<ol>
<li>
<p><strong>Limitations of Feature Pyramids</strong></p>
<p>Traditional feature pyramid strategies, prevalent in the era of handcrafted features, were the primary tools for recognizing multi-scale objects. However, in the era of deep learning, these methods no longer suffice for current needs. Their main issue is their relatively weak ability to process features of different scales. Especially when dealing with large amounts of image data, their processing speed is far from meeting real-time application requirements. Additionally, these methods only perform simple feature scaling without deeper feature fusion and optimization, limiting their recognition effectiveness.</p>
</li>
<li>
<p><strong>Limitations of SSD</strong></p>
<p>In order to address the above problems, SSD, as an emerging strategy, attempts to utilize the pyramid feature hierarchy of deep convolutional networks. Its goal is to completely replace traditional feature pyramid strategies. However, SSD has some obvious flaws in its design. In order to avoid using lower-level features, it deliberately does not reuse high-resolution layers that have already been computed, instead opting to add new layers to build its pyramid. This approach not only increases computational complexity but also overlooks the importance of high-resolution mappings in the feature hierarchy. For detecting small objects, these high-resolution mappings are crucial, which SSD&#x27;s strategy clearly ignores.</p>
</li>
</ol>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="solution">Solution<a href="#solution" class="hash-link" aria-label="Direct link to Solution" title="Direct link to Solution">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="fpn-model-design">FPN Model Design<a href="#fpn-model-design" class="hash-link" aria-label="Direct link to FPN Model Design" title="Direct link to FPN Model Design">​</a></h3>
<p><img decoding="async" loading="lazy" alt="fpn_3" src="/en/assets/images/fpn_3-8343b88168361c005df0ee97a372bbf8.jpg" width="1024" height="887" class="img_ev3q"></p>
<p>The main purpose of FPN is to improve upon the design of SSD. The authors propose a structure, as shown in the above figure, to create a feature pyramid with strong semantics at all scales while maintaining the pyramid-shaped hierarchical structure of convolutional network features.</p>
<p>To achieve this goal, the authors design a structure:</p>
<ul>
<li><strong>Combine low-resolution features with high-resolution features through top-down pathways and lateral connections.</strong></li>
</ul>
<p>In fact, once this sentence is explained, the paper is essentially concluded, as what follows is just implementation and testing.</p>
<p>However, we can still look at some implementation details provided by the authors.</p>
<ol>
<li>
<p><strong>Bottom-up pathway</strong></p>
<p><img decoding="async" loading="lazy" alt="fpn_2" src="/en/assets/images/fpn_2-c3d635c32d5e688c8cd4718addfd29a7.jpg" width="1024" height="396" class="img_ev3q"></p>
<p>The first part is called the data path from Bottom features to Top features. Since this paper does not provide image references, I hand-drew an architecture diagram and inserted actual numbers, simplifying the information as much as possible to illustrate the flow of data within the model:</p>
<p>Taking ResNet18 as an example, inputting a 224 x 224 x 3 image. Since we use PyTorch syntax, the number of channels comes first. After passing through ResNet18, we get five different resolution feature maps. Here, let&#x27;s define these feature maps:</p>
<ul>
<li>P1: Feature map at 1/2 scale, size 64 x 112 x 112.</li>
<li>P2: Feature map at 1/4 scale, size 64 x 56 x 56.</li>
<li>P3: Feature map at 1/8 scale, size 128 x 28 x 28.</li>
<li>P4: Feature map at 1/16 scale, size 256 x 14 x 14.</li>
<li>P5: Feature map at 1/32 scale, size 512 x 7 x 7.</li>
</ul>
<p>This image goes through the downsampling process of the model, referred to as the Bottom-up pathway in this paper.</p>
<p>It&#x27;s worth noting that in most model architecture designs, P1 and P2 feature maps are not used to construct the feature pyramid because these two feature maps still have very large dimensions and would consume a lot of computational resources.</p>
</li>
<li>
<p><strong>Top-down pathway and lateral connections</strong></p>
<p>Reflecting on the previous steps, data flow starts from the left and moves to the right.</p>
<p>In the second stage of feature pyramid design, the goal is to merge features &quot;from right to left&quot;.</p>
<p>So let&#x27;s zoom in on the P4 – P5 section we just discussed:</p>
<p><img decoding="async" loading="lazy" alt="fpn_3" src="/en/assets/images/fpn_7-f85c22c3c6fe9e3c51d4d9fc8bc59b0c.jpg" width="1140" height="828" class="img_ev3q"></p>
<p>In this fusion process, first, because high-dimensional feature maps have smaller dimensions, we need to address them first.</p>
<p>Here, we perform an Upsample operation on the P5 feature map to ensure size consistency.</p>
<p>Next, we want to add these two feature maps with different dimensions. However, this poses another challenge: the channel numbers do not match.</p>
<p>As shown in the figure above, the feature map output from Block5 has 512 channels, while the feature map output from Block4 only has 256 channels. Due to the mismatch in channel numbers, direct addition operations cannot be performed. To solve this problem, we need to use 1×1 convolutional kernels to adjust the number of channels in the feature maps. Note that there is no fixed rule for adjusting the number of channels; you can define a suitable number of channels based on the actual situation, such as setting it to 64.</p>
<p>Each P1～P5 feature map needs to pass through a 1×1 convolutional layer to ensure consistent channel numbers, thus avoiding alignment issues.</p>
<p>After ensuring channel alignment and size consistency, we can directly add feature maps from different layers to complete a round of fusion operations.</p>
<p>If this step is repeated, it might give you a better understanding. So let&#x27;s look at the fusion from P4 to P3 again.</p>
<p><img decoding="async" loading="lazy" alt="fpn_5" src="/en/assets/images/fpn_5-9d164ae1834a36be83c64d1262a3b821.jpg" width="1024" height="392" class="img_ev3q"></p>
<p>Finally, here&#x27;s a more straightforward architecture design that is easier to implement:</p>
<p><img decoding="async" loading="lazy" alt="fpn_6" src="/en/assets/images/fpn_6-29914d6ce938ac71055641c746b66e9a.jpg" width="1024" height="346" class="img_ev3q"></p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>Scaling each scale&#x27;s feature maps first and then performing feature fusion is a common design approach in engineering implementation.</p></div></div>
</li>
</ol>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="discussion">Discussion<a href="#discussion" class="hash-link" aria-label="Direct link to Discussion" title="Direct link to Discussion">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="is-this-really-better">Is this really better?<a href="#is-this-really-better" class="hash-link" aria-label="Direct link to Is this really better?" title="Direct link to Is this really better?">​</a></h3>
<p>Directly speaking about the results: yes, it is.</p>
<p>The paper&#x27;s authors conducted numerous sets of experimental data to argue this point. At the end of the article, let&#x27;s pick out a few key figures to take a look at. Let&#x27;s first examine the ablation experiments provided in the paper, as shown in the table below:</p>
<p><img decoding="async" loading="lazy" alt="fpn_4" src="/en/assets/images/fpn_4-11a1be8958d93fbeb388f60f6f00c1a4.jpg" width="1024" height="231" class="img_ev3q"></p>
<p>This table first discusses removing different components, where (d) removes the top-down component; (e) removes lateral connections; and (f) changes the representation of the feature pyramid. It can be observed that removing any component leads to a significant decrease in performance, with marginal differences from the baseline comparison model.</p>
<p>Next, let&#x27;s look at the next table:</p>
<p><img decoding="async" loading="lazy" alt="fpn_1" src="/en/assets/images/fpn_1-806ea6b48d355fcaea10b6ebeea1065c.jpg" width="1024" height="218" class="img_ev3q"></p>
<p>The authors of this paper compared their method with the single-model results of the COCO competition winners, including the 2016 winner G-RMI and the 2015 winner Faster R-CNN+++. Without using various fancy techniques, FPN&#x27;s single model already surpasses these powerful, carefully designed competitors. On the test development set, FPN outperforms the existing best results by 0.5 points AP.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>FPN proposes a concise framework that can be combined with various backbone networks to construct powerful feature pyramids. This method shows significant improvements over multiple strong baseline models and competition winners.</p>
<p>This paper on FPN discusses two things:</p>
<ul>
<li>Firstly, whenever the problem to be solved exhibits multiscale characteristics, different-scale feature fusion techniques must be considered.</li>
<li>Secondly, feature fusion techniques boil down to three sentences: &quot;bottom to top, top to bottom, then add them together.&quot;</li>
</ul>
<p>Following this paper, many directions for discussion have emerged, such as: how to design better feature fusion strategies? How to improve the efficiency of fusion? Or how to adjust fusion weights? Various scenarios like these have been explored in subsequent papers. We&#x27;ll look at them together when we have time.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2024-04-28T22:02:45.000Z" itemprop="dateModified">Apr 28, 2024</time></b> by <b>zephyr-sh</b></span></div></div></footer><div style="margin-top:3rem"> </div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/en/papers/category/featurefusion"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">FeatureFusion</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/en/papers/feat-fusion/panet"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">PANet</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#pyramid-architecture" class="table-of-contents__link toc-highlight">Pyramid Architecture</a></li><li><a href="#problem-definition" class="table-of-contents__link toc-highlight">Problem Definition</a></li><li><a href="#solution" class="table-of-contents__link toc-highlight">Solution</a><ul><li><a href="#fpn-model-design" class="table-of-contents__link toc-highlight">FPN Model Design</a></li></ul></li><li><a href="#discussion" class="table-of-contents__link toc-highlight">Discussion</a><ul><li><a href="#is-this-really-better" class="table-of-contents__link toc-highlight">Is this really better?</a></li></ul></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class="footer__links"><a class="footer__link-item" href="/en/docs">Docs</a><span class="footer__link-separator">·</span><a class="footer__link-item" href="/en/papers/intro">Papers</a><span class="footer__link-separator">·</span><a class="footer__link-item" href="/en/blog">Blog</a><span class="footer__link-separator">·</span><a href="https://github.com/DocsaidLab" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><span class="footer__link-separator">·</span><a href="https://docsaid.org/blog/terms-of-service" target="_blank" rel="noopener noreferrer" class="footer__link-item">TermsOfUse<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><span class="footer__link-separator">·</span><a href="https://docsaid.org/blog/privacy-policy" target="_blank" rel="noopener noreferrer" class="footer__link-item">Privacy Policy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 DOCSAID.</div></div></div></footer></div>
</body>
</html>