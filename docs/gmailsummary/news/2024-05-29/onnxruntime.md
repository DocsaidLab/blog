# onnxruntime

## 2024-05-29 彙整報告

根據您提供的郵件內容，這裡有一些重要的訊息提取：



### 1. 錯誤修復:

- 在arm64主機上使用`--arm64`或`--arm64ec`標誌時需要自定義protoc執行文件的問題得到修正，這將有助於改善在特定主機上的編譯流程。

- 修正了使用`_kOrtRunOptionsConfigEnableMemoryArenaShrinkage_`運行選項時出現的錯誤，這可能影響了CoreML插件的功能性。



### 2. 功能增加:

- 新增了有關如何從C++和Python分配CUDA設備張量的文檔，這將有助於用戶更有效地管理CUDA設備。

- 提出了在 `session.run()` 中支持bfloat16/float8輸入的功能請求，這可能會擴展ONNXruntime的數據類型支持範圍。



### 3. 討論的議題:

- 討論了在共享庫EP的“EP上下文”功能開發中需要將`IndexedSubGraph`轉換為`FunctionProto`的議題，這可能涉及到模型優化和運行時的相關調整。

- 討論了模型運行在所有操作完成後仍花費大量時間的問題，這可能需要進一步優化模型運行時的效率。



### 4. 特別提到的成就或挑戰:

- 提到了硬件供應商對於具有外部圖形轉換器以實驗新融合的興趣，這可能意味著在硬件層面上有新的優化和功能實驗。

- 討論了如何在CUDA流中捕獲CUDA圖形以減少CPU上的CUDA啟動延遲，這可能是為了提高CUDA運行效率而探討的技術挑戰。



在這些訊息中，錯誤修復和功能增加展示了持續改進和擴展ONNXruntime功能的努力。討論的議題則涉及到模型優化和運行時效率的議題，這對於提高模型性能和效率至關重要。特別提到的成就或挑戰反映了對於硬件優化和性能提升的關注，這將有助於ONNXruntime在不同硬件平台上的應用和性能表現。



對於一些專有名詞的解釋：

- CUDA：一種由NVIDIA開發的並行計算平台和應用程式程式設計接口，用於加速應用程式的運算。

- CoreML：蘋果公司的機器學習框架，用於在iOS和macOS設備上運行機器學習模型。

- EP（Execution Provider）：ONNXruntime中的執行提供者，負責在特定硬件上執行模型的計算。

- CUDA流（CUDA Stream）：CUDA中用於管理並行操作的流水線，可實現GPU上的非阻塞操作。

- 融合（Fusion）：指將多個計算步驟合併為單個步驟以提高效率和性能。

- 模型優化（Model Optimization）：通過調整模型結構和運行時參數以提高模型性能和效率。

- 硬件供應商（Hardware Vendor）：生產和提供硬件設備的公司或組織，如NVIDIA、Intel等。



---



本日共彙整郵件： 82 封



以上報告由 OpenAI GPT-3.5 Turbo 模型自動生成。