# [20.05] GPT-3

## 九十六層解碼器

[**Language Models are Few-Shot Learners**](https://arxiv.org/abs/2005.14165)

---

:::info
以下內容由 ChatGPT-4 彙整，並經過人工校對編輯與補充說明。
:::

---

第二代的 GPT 疊了四十八層 Transformer 解碼器。

OpenAI 覺得這樣不夠，於是他們疊了九十六層 Transformer 解碼器，這就是 GPT-3。

## 定義問題

## 解決問題

## 討論

## 結論

這個模型的規模之大，以至於 OpenAI 在發布時擔心它可能被濫用，因此他們決定不公開釋出完整的模型。
